{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8640cd84",
   "metadata": {},
   "source": [
    "# INF264 - Project 1: Implementing Decision Trees\n",
    "=========================================================================\n",
    "\n",
    "A machine learning project for implementing decision trees as part of the INF264 course.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [0.1 Imports and Data Loading](#0.1-Imports-and-Data-Loading)\n",
    "- [0.2 Data Analysis and Preprocessing](#0.2-Data-Analysis-and-Preprocessing)\n",
    "- [1.1 Implement a Decision Tree Learning Algorithm, From Scratch](#1.1-Implement-a-Decision-Tree-Learning-Algorithm,-From-Scratch)\n",
    "- [1.2 Add Gini Index](#1.2-Add-Gini-Index)\n",
    "- [1.3 Add Reduced-Error Pruning](#1.3-Add-Reduced-Error-Pruning)\n",
    "- [1.4 Evaluate Your Algorithm](#1.4-Evaluate-Your-Algorithm)\n",
    "- [1.5 Compare to an Existing Implementation](#1.5-Compare-to-an-Existing-Implementation)\n",
    "\n",
    "## 0.1 Imports and Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb958617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "# Load the dataset from a CSV file into a DataFrame.\n",
    "data = pd.read_csv(\"wine_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08821d",
   "metadata": {},
   "source": [
    "## 0.2 Data Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec01568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and labels.\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bacd463f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.13</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.32</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>13.65</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.74</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   citric acid  residual sugar    pH  sulphates  alcohol  type\n",
       "0         0.13            1.60  3.34       0.59      9.2     1\n",
       "1         0.10            2.80  3.60       0.66     10.2     1\n",
       "2         0.32            1.90  3.20       0.55      9.5     1\n",
       "3         0.29           13.65  3.00       0.60      9.5     0\n",
       "4         0.26            2.00  3.41       0.74      9.2     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eae04a",
   "metadata": {},
   "source": [
    "The dataset consists of the features: 'citric acid', 'residual sugar', 'pH', 'sulphates', and 'alcohol', and the binary target 'type'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29fa68e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citric acid       float64\n",
       "residual sugar    float64\n",
       "pH                float64\n",
       "sulphates         float64\n",
       "alcohol           float64\n",
       "type                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the types of each feature/label.\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d582d0",
   "metadata": {},
   "source": [
    "The features are encoded as floats and the target is encoded as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57e955c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citric acid       0\n",
       "residual sugar    0\n",
       "pH                0\n",
       "sulphates         0\n",
       "alcohol           0\n",
       "type              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values.\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4dd1e9",
   "metadata": {},
   "source": [
    "The dataset does not contain any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571607ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3198.000000</td>\n",
       "      <td>3198.000000</td>\n",
       "      <td>3198.000000</td>\n",
       "      <td>3198.000000</td>\n",
       "      <td>3198.000000</td>\n",
       "      <td>3198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.301776</td>\n",
       "      <td>4.449781</td>\n",
       "      <td>3.249678</td>\n",
       "      <td>0.574431</td>\n",
       "      <td>10.459725</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.165284</td>\n",
       "      <td>4.214445</td>\n",
       "      <td>0.163439</td>\n",
       "      <td>0.165587</td>\n",
       "      <td>1.143231</td>\n",
       "      <td>0.500078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.210000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>3.360000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       citric acid  residual sugar           pH    sulphates      alcohol   \n",
       "count  3198.000000     3198.000000  3198.000000  3198.000000  3198.000000  \\\n",
       "mean      0.301776        4.449781     3.249678     0.574431    10.459725   \n",
       "std       0.165284        4.214445     0.163439     0.165587     1.143231   \n",
       "min       0.000000        0.600000     2.740000     0.220000     8.000000   \n",
       "25%       0.210000        1.900000     3.140000     0.470000     9.500000   \n",
       "50%       0.300000        2.400000     3.240000     0.550000    10.200000   \n",
       "75%       0.400000        5.937500     3.360000     0.650000    11.200000   \n",
       "max       1.660000       65.800000     4.010000     2.000000    14.900000   \n",
       "\n",
       "              type  \n",
       "count  3198.000000  \n",
       "mean      0.500000  \n",
       "std       0.500078  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.500000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a57f3",
   "metadata": {},
   "source": [
    "There might be some outliers. For example in 'residual sugar' there are a big difference between the max and 75%, which may indicate outliers. This does not matter since decision trees are not sensitive to outliers. \n",
    "\n",
    "The dataset is not normalized because the features are not between 0 and 1. Normalizations is also not needed for decision trees because they make their decisions (splits) on one feature at a time. Meaning they are not sensitive to variance in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01399c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "1    0.5\n",
       "0    0.5\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the proportions between each label.\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076fc6b",
   "metadata": {},
   "source": [
    "The dataset is perfectly balanced as all things should be.\n",
    "\n",
    "The dataset has been split into features (X) and target/labels (y). And will later be split into training, validation, testing and pruning sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd2829f",
   "metadata": {},
   "source": [
    "# 1.1 Implement a Decision Tree Learning Algorithm, From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60595548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    \"\"\"Represents a node in a decision tree.\n",
    "    \n",
    "    The node stores the criteria (feature and threshold) for splitting the data into two children.\n",
    "    It recursively directs the data point left or right to predict.\n",
    "    \n",
    "    Attributes:\n",
    "        feature_index (int): Index of the feature used for splitting.\n",
    "        threshold (float): The threshold value used for splitting.\n",
    "        left (DecisionNode or Leaf): Left child (subtree) for values <= threshold.\n",
    "        right (DecisionNode or Leaf): Right child (subtree) for values > threshold.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_index, threshold, left, right):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict label for the given data point.\n",
    "        \n",
    "        Recursively goes though the decision tree, based on the features value and the corresponding threshold.\n",
    "        \n",
    "        Args:\n",
    "            x (Series): A single data point.\n",
    "            \n",
    "        Returns:\n",
    "            int: Predicted class label.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # If the value of the feature at index 'feature_index' for the datapoint x \n",
    "        # is less than or equal to the threshold value, go left.\n",
    "        if x[self.feature_index] <= self.threshold:\n",
    "            return self.left.predict(x)\n",
    "        # Else, go right. \n",
    "        else:\n",
    "            return self.right.predict(x)\n",
    "\n",
    "class Leaf:\n",
    "    \"\"\"Represents a leaf node in a decision tree.\n",
    "    \n",
    "    The leaf contains the final predicted label, and has no children.\n",
    "    \n",
    "    Attributes:\n",
    "        label (int or str): Predicted label.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Return the predicted label stored in this leaf.\n",
    "        \n",
    "        Args:\n",
    "            x (Series): A single data point (not used in the method, but included for consistency).\n",
    "        \n",
    "        Returns:\n",
    "            int or str: Predicted label.\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84ca904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identical_labels(y):\n",
    "    \"\"\"Check if all labels are identical.\n",
    "    \n",
    "    Args:\n",
    "        y (Series): Series containing labels.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if all labels are identical, False if not.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return y.nunique() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95869cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identical_features(X):\n",
    "    \"\"\"Check if all values within each feature column are identical.\n",
    "    \n",
    "    Args:\n",
    "        X (DataFrame): DataFrame containing features.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if all values within each feature column are identical, False if not.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return (X.nunique() == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdc475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    \"\"\"Calculate the entropy of given labels.\n",
    "    \n",
    "    Args:\n",
    "        y (Series): Series of labels.\n",
    "    \n",
    "    Returns:\n",
    "        float: The entropy value for the provided labels.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the counts of all the labels\n",
    "    labels, counts = np.unique(y, return_counts=True)\n",
    "    \n",
    "    # Calculate the total number of labels\n",
    "    total_labels = len(y)\n",
    "    \n",
    "    # Calculate entropy\n",
    "    probabilities = counts / total_labels\n",
    "    return -np.sum(probabilities * np.log2(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f33f462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(y, y_left, y_right, impurity_measure='entropy'):\n",
    "    \"\"\"Calculate the information gain.\n",
    "    \n",
    "    The information gain is the reduction in uncertainty (uncertainty before split - uncertainty after split).\n",
    "    \n",
    "    Args:\n",
    "        y (Series): Series containing labels.\n",
    "        y_left (Series): Series containing labels for the left split.\n",
    "        y_right (Series): Series containing labels for the right split.\n",
    "        impurity_measure (str, optional): The measure used to determine which impurity measure to use.\n",
    "            Default is 'entropy'.\n",
    "    \n",
    "    Returns:\n",
    "        float: The information gain value for the provided split. \n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the provided impurity_measure is not in the impurity_measures dictionary.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary holding the different impurity measures.\n",
    "    impurity_measures = {\n",
    "        'entropy': entropy,\n",
    "        'gini': gini\n",
    "    }\n",
    "    \n",
    "    # Raise an error if the given impurity_measure is not in the impurity_measures dictionary.\n",
    "    if impurity_measure not in impurity_measures:\n",
    "        raise ValueError(f'Invalid impurity_measure: \\'{impurity_measure}\\'. Available impurity measures: {list(impurity_measures.keys())}')\n",
    "    \n",
    "    # Calculate the original impurity.\n",
    "    original_impurity = impurity_measures[impurity_measure](y)\n",
    "    \n",
    "    # Calculate the impurity for the \"left\" and \"right\" split.\n",
    "    left_measure = impurity_measures[impurity_measure](y_left)\n",
    "    right_measure = impurity_measures[impurity_measure](y_right)\n",
    "    \n",
    "    # Calculate the proportions of data points in the left and right splits    \n",
    "    prop_left = len(y_left) / len(y)\n",
    "    prop_right = len(y_right) / len(y)\n",
    "    \n",
    "    # Calculate the new (average weighted) impurity measure\n",
    "    new_impurity = prop_left * left_measure + prop_right * right_measure\n",
    "    \n",
    "    # Return the information gain\n",
    "    return original_impurity - new_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1757b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X_train, y_train, impurity_measure):\n",
    "    \"\"\"Recursively build a decision tree based on the provided data and impurity measure.\n",
    "    \n",
    "    Args:\n",
    "        X_train (DataFrame): DataFrame containing training features.\n",
    "        y_train (Series): Series containing training labels.\n",
    "        impurity_measure (str, optional): The measure used to determine which impurity measure to use.\n",
    "            Default is 'entropy'.\n",
    "            \n",
    "    Returns:\n",
    "        Node: A DecisionNode (if there are a valid split), or a Leaf.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If X_train and y_train are empty or different sizes.\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    # Raise an error if the given X and y is empty or different sizes. \n",
    "    if X_train.shape[0] == 0 or y_train.shape[0] == 0:\n",
    "        raise ValueError('X or y is empty.')\n",
    "    if X_train.shape[0] != y_train.shape[0]:\n",
    "        raise ValueError('X and y is not the same size.')\n",
    "    \n",
    "    # Check if all the labels are the same. If true, return a Leaf node with that label.\n",
    "    if identical_labels(y_train):\n",
    "        return Leaf(y_train.iloc[0])\n",
    "\n",
    "    # Check if all features values across all instances are the same.\n",
    "    # If True, get the most common value (if multiple labels are equally common, the first one is chosen).\n",
    "    # Return a Leaf node with the most common label. \n",
    "    elif identical_features(X_train):\n",
    "        most_common_label = y_train.mode().iloc[0]\n",
    "        return Leaf(most_common_label)\n",
    "    \n",
    "    # Set initial variables to 0 and None. \n",
    "    best_gain = 0\n",
    "    best_split = None\n",
    "    best_left_indices = None\n",
    "    best_right_indices = None\n",
    "\n",
    "    # For each feature in the X_train:\n",
    "    for feature in range(X_train.shape[1]):\n",
    "        # Get the feature values from the current feature in X_train.\n",
    "        values = X_train.iloc[:, feature]\n",
    "        \n",
    "        # Calculate the median of the feature values. \n",
    "        median_value = values.median()\n",
    "        \n",
    "        # Split the feature indicies based on the median value. \n",
    "        left_indices = np.where(values < median_value)[0]\n",
    "        right_indices = np.where(values >= median_value)[0]\n",
    "        \n",
    "        # Get the labels from the splits using the indices.\n",
    "        y_train_left = y_train.iloc[left_indices]\n",
    "        y_train_right = y_train.iloc[right_indices]\n",
    "        \n",
    "        # Get the information gain for the split.\n",
    "        gain = information_gain(y_train, y_train_left, y_train_right, impurity_measure)\n",
    "\n",
    "        # If the current split is better than the previous best split, update the variables.\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_split = feature, median_value\n",
    "            best_left_indices = left_indices\n",
    "            best_right_indices = right_indices\n",
    "\n",
    "    # If the best gain is 0, there is no benefit to split. Return a leaf with the most common value.\n",
    "    if best_gain == 0:\n",
    "        return Leaf(y_train.value_counts().idxmax())\n",
    "\n",
    "    # Recursively create the left and right children (subtrees) using the best split.\n",
    "    left_tree = build_tree(X_train.iloc[best_left_indices, :], y_train.iloc[best_left_indices], impurity_measure)\n",
    "    right_tree = build_tree(X_train.iloc[best_right_indices, :], y_train.iloc[best_right_indices], impurity_measure)\n",
    "    \n",
    "    # Return a new decision node with the best split feature, threshold (median) and the left and right subtree.\n",
    "    return DecisionNode(best_split[0], best_split[1], left_tree, right_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39a3b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(X, y, impurity_measure='entropy', prune=False, pruning_set_size=0.1, pruning_threshold=0):\n",
    "    \"\"\"Trains a decision tree using the provided X and y. Optionally prunes the tree.\n",
    "\n",
    "    Args:\n",
    "        X (DataFrame): The dataframe containing the features.\n",
    "        y (Series): The labels corresponding to each sample in X.\n",
    "        impurity_measure (str, optional): The measure used to determine which impurity measure to use.\n",
    "            Default is 'entropy'.\n",
    "        prune (bool, optional): Whether to prune the tree or not. \n",
    "            Default is False.\n",
    "        pruning_set_size (float, optional): If pruning is enabled, this is the ratio of the dataset \n",
    "            to use for the pruning set. Default is 0.1 (10%).\n",
    "        pruning_threshold (float): The amount that the accuracy need to improve before we prune.\n",
    "            Default is 0.\n",
    "\n",
    "    Returns:\n",
    "        DecisionNode: The root node of the decision tree.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `X` or `y` is empty, or if they are not the same size.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Raise an error if the given X and y is empty or different sizes. \n",
    "    if X.shape[0] == 0 or y.shape[0] == 0:\n",
    "        raise ValueError('X or y is empty.')\n",
    "    if X.shape[0] != y.shape[0]:\n",
    "        raise ValueError('X and y is not the same size.')\n",
    "    \n",
    "    # If prune is true:\n",
    "    if prune:\n",
    "        # Split the data into training and pruning sets.\n",
    "        X_train, X_prune, y_train, y_prune = train_test_split(X, y, test_size=pruning_set_size, random_state=42)\n",
    "        \n",
    "        # Build the decision tree.\n",
    "        tree = build_tree(X_train, y_train, impurity_measure)\n",
    "        \n",
    "        # Prune the tree and return it.\n",
    "        pruned_tree = prune_tree(tree, X_train, y_train, X_prune, y_prune, pruning_threshold)\n",
    "        return pruned_tree\n",
    "    \n",
    "    # If prune is false, build and return the decision tree.\n",
    "    else:\n",
    "        tree = build_tree(X, y, impurity_measure)\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a099948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_stats(tree):\n",
    "    \"\"\"Compute total number of nodes, leaves and max depth of a given tree.\n",
    "    \n",
    "    Args:\n",
    "        tree (DecisionNode or Leaf): Root node of a tree.\n",
    "    \n",
    "    Returns:\n",
    "        tuple:\n",
    "            - maximum depth\n",
    "            - total number of leaves\n",
    "            - total number of nodes\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(tree, Leaf):\n",
    "        return 0, 1, 1 # depth, leaf, node\n",
    "    \n",
    "    # Recursively compute the depth, number of leaves and number of nodes for left and right subtree.\n",
    "    left_depth, left_leaves, left_nodes = tree_stats(tree.left)\n",
    "    right_depth, right_leaves, right_nodes = tree_stats(tree.right)\n",
    "    \n",
    "    # Get the max depth of left and right subtree.\n",
    "    max_depth = 1 + max(left_depth, right_depth)\n",
    "    \n",
    "    # Sum total number of leaves in the left and right subtree to get the total number of leaves. \n",
    "    total_leaves = left_leaves + right_leaves \n",
    "    \n",
    "    # Sum total number of nodes in the left and right subtree and add 1 (the current node) to get total number of nodes.\n",
    "    total_nodes = 1 + left_nodes + right_nodes\n",
    "    \n",
    "    return max_depth, total_leaves, total_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa5328f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree_stats(tree):\n",
    "    \"\"\" Compute and print the statistics of a given decision tree.\n",
    "    \n",
    "    Args:\n",
    "        node (DecisionNode or Leaf): The root node of a decision tree.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    max_depth, total_leaves, total_nodes = tree_stats(tree)\n",
    "    print(f'Number of nodes: {total_nodes}')\n",
    "    print(f'Number of leaf nodes: {total_leaves}')\n",
    "    print(f'Depth of the tree: {max_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451a684",
   "metadata": {},
   "source": [
    "# 1.2 Add Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3650d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y):\n",
    "    \"\"\"Calculate the Gini of given labels.\n",
    "    \n",
    "    Args:\n",
    "        y (Series): Series of labels\n",
    "        \n",
    "    Returns:\n",
    "        float: The Gini value for the provided labels.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the counts of all the labels\n",
    "    labels, counts = np.unique(y, return_counts=True)\n",
    "    \n",
    "    # Calculate the total number of labels\n",
    "    total_labels = len(y)\n",
    "    \n",
    "    # Calculate Gini\n",
    "    probabilities = counts / total_labels\n",
    "    return 1-np.sum(probabilities ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f7e05",
   "metadata": {},
   "source": [
    "# 1.3 Add Reduced-Error Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66e4ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(node, X):\n",
    "    \"\"\"Get predictions for a dataset using given node.\n",
    "    \n",
    "    Args:\n",
    "        node (DecisionNode or Leaf): The node used for prediction.\n",
    "        X (DataFrame): The dataset.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of predictions for each row in the DataFrame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    # Iterates through each row in the DataFrame X.\n",
    "    for _, x in X.iterrows():\n",
    "        # Predict the label for the current row using the provided node.\n",
    "        prediction = node.predict(x)\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39dbd606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_tree(node, X_train, y_train, X_prune, y_prune, pruning_threshold=0):\n",
    "    \"\"\"Recursively prune the decision tree.\n",
    "    \n",
    "    Args:\n",
    "        node (DecisionNode or Leaf): The original (pre-pruning) node or child.\n",
    "        X_prune (DataFrame): The features of the pruning dataset.\n",
    "        y_prune (Series): The labels of the pruning dataset.\n",
    "        pruning_threshold (float): The amount that the accuracy need to improve before we prune.\n",
    "            Default is 0.\n",
    "    \n",
    "    Returns:\n",
    "        DecisionNode or Leaf: The pruned node or child.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if it is a leaf node. If it is, no pruning is needed (there is nothing to prune). \n",
    "    if isinstance(node, Leaf):\n",
    "        return node\n",
    "    \n",
    "    # If it's a DecisionNode, prune its children. This makes it recursive, and makes it a buttom-up approach.\n",
    "    node.left = prune_tree(node.left, X_train, y_train, X_prune, y_prune, pruning_threshold=pruning_threshold)\n",
    "    node.right = prune_tree(node.right, X_train, y_train, X_prune, y_prune, pruning_threshold=pruning_threshold)\n",
    "\n",
    "    # Get the column name from the feature index\n",
    "    feature_name = X_prune.columns[node.feature_index]\n",
    "    \n",
    "    # Filter the pruning dataset based on the decision at the current node\n",
    "    left_filter = X_prune[feature_name] <= node.threshold\n",
    "    right_filter = X_prune[feature_name] > node.threshold\n",
    "\n",
    "    left_data = y_prune[left_filter]\n",
    "    right_data = y_prune[right_filter]\n",
    "\n",
    "    # Make a prediction with the original tree structure.\n",
    "    original_predictions = get_predictions(node, X_prune)\n",
    "        \n",
    "    # Calculate the accuracy before pruning.    \n",
    "    original_accuracy = sum(original_predictions == y_prune) / len(y_prune)\n",
    "    \n",
    "    # Find the majority class of the labels in the pruning set. Create a new leaf node with this class.\n",
    "    majority_class = pd.concat([y_prune[left_filter], y_prune[right_filter]]).mode().iloc[0]\n",
    "    leaf_node = Leaf(majority_class)\n",
    "    \n",
    "    # Make a prediction using the pruned child.\n",
    "    pruned_predictions = get_predictions(leaf_node, X_prune)\n",
    "    \n",
    "    # Calculate the accuracy after pruning (the accuracy if the original node is replaced by the new leaf node).\n",
    "    pruned_accuracy = sum(pruned_predictions == y_prune) / len(y_prune)\n",
    "    \n",
    "    # If replacing the child with the new leaf node does not decrease accuracy, replace the child with the leaf node.\n",
    "    if pruned_accuracy >= original_accuracy + pruning_threshold:\n",
    "        return leaf_node\n",
    "    else:\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54128f3a",
   "metadata": {},
   "source": [
    "# 1.4 Evaluate Your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4cd476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X (features) and y (labels).\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Split the data into a temporary and a training test set.\n",
    "# Then split the temporary set into validation and testing set.\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c035bb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>0.38</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>0.23</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0.04</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>0.20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>0.32</td>\n",
       "      <td>16.2</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.59</td>\n",
       "      <td>11.8</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.46</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.30</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.36</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>0.39</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.71</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2558 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      citric acid  residual sugar    pH  sulphates  alcohol\n",
       "3034         0.38             8.1  3.30       0.54      9.8\n",
       "2576         0.23             6.2  3.34       0.43      9.6\n",
       "533          0.04             2.5  3.53       0.55      9.5\n",
       "1061         0.20             3.0  3.23       0.59      9.5\n",
       "2626         0.32            16.2  3.17       0.37     11.2\n",
       "...           ...             ...   ...        ...      ...\n",
       "1095         0.59            11.8  3.17       0.46      8.9\n",
       "1130         0.30             1.2  2.96       0.36     12.5\n",
       "1294         0.00             2.2  3.40       0.58     10.9\n",
       "860          0.14             2.4  3.66       0.65      9.8\n",
       "3174         0.39             3.2  3.37       0.71     11.5\n",
       "\n",
       "[2558 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dabcd0d",
   "metadata": {},
   "source": [
    "### 1.4.1 Model Training and Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "782ce332",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "\u001b[1mEntropy with pruning\u001b[0m \n",
      "Accuracy: 0.7906\n",
      "F1 score: 0.8154\n",
      "Number of nodes: 375\n",
      "Number of leaf nodes: 188\n",
      "Depth of the tree: 12\n",
      "-----------------------------------\n",
      "\u001b[1mEntropy without pruning\u001b[0m \n",
      "Accuracy: 0.8562\n",
      "F1 score: 0.8477\n",
      "Number of nodes: 989\n",
      "Number of leaf nodes: 495\n",
      "Depth of the tree: 13\n",
      "-----------------------------------\n",
      "\u001b[1mGini with pruning\u001b[0m \n",
      "Accuracy: 0.7688\n",
      "F1 score: 0.8000\n",
      "Number of nodes: 361\n",
      "Number of leaf nodes: 181\n",
      "Depth of the tree: 11\n",
      "-----------------------------------\n",
      "\u001b[1mGini without pruning\u001b[0m \n",
      "Accuracy: 0.8781\n",
      "F1 score: 0.8713\n",
      "Number of nodes: 977\n",
      "Number of leaf nodes: 489\n",
      "Depth of the tree: 13\n",
      "-----------------------------------\n",
      "\u001b[1mBest model: Gini without pruning\u001b[0m\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of impurity measures and pruning settings (with or without) to test.\n",
    "settings_measures = ['entropy', 'gini']\n",
    "settings_pruning = [True, False]\n",
    "\n",
    "# Variables to keep track of the best performing tree, impurity measure, prune setting and accuracy.\n",
    "best_tree = None\n",
    "best_measure = 0\n",
    "best_prune_setting = False\n",
    "best_accuracy = 0\n",
    "\n",
    "print('-' * 35)\n",
    "\n",
    "# Loop through each impurity measure with each prune setting. \n",
    "for measure in settings_measures:    \n",
    "    for prune in settings_pruning:\n",
    "        # Train the decision tree using the current settings.\n",
    "        tree = learn(X_train, y_train, impurity_measure=measure, prune=prune)\n",
    "        \n",
    "        # Make a prediction using validation data.\n",
    "        predictions = get_predictions(tree, X_val)\n",
    "        \n",
    "        # Calculate the accuracy of the predictions. \n",
    "        accuracy = sum(predictions == y_val) / len(y_val)\n",
    "        \n",
    "        # Calculate the F1 score of the predictions.\n",
    "        f1 = f1_score(y_val, predictions)\n",
    "        \n",
    "        # If accuracy improves, update best_measure, best_accuracy, best_prune_setting and best_tree\n",
    "        # to the current values.\n",
    "        if accuracy > best_accuracy:\n",
    "            best_measure = measure\n",
    "            best_accuracy = accuracy\n",
    "            best_prune_setting = prune\n",
    "            best_tree = tree\n",
    "        \n",
    "        # Print the results with the current settings.\n",
    "        pruning_status = 'with pruning' if prune else 'without pruning'\n",
    "        print(f'\\033[1m{measure.capitalize()} {pruning_status}\\033[0m ')\n",
    "        print(f'Accuracy: {accuracy:.4f}')\n",
    "        print(f'F1 score: {f1:.4f}')\n",
    "        print_tree_stats(tree)\n",
    "        print('-' * 35)\n",
    "\n",
    "# Print the best model and the result.\n",
    "pruning_status = 'with pruning' if best_prune_setting else 'without pruning'        \n",
    "print(f'\\033[1mBest model: {best_measure.capitalize()} {pruning_status}\\033[0m')\n",
    "print('-' * 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11cf657",
   "metadata": {},
   "source": [
    "* Entropy with pruning vs without pruning:\n",
    "    - Accuracy with pruning ≈ 0.79\n",
    "    - Accuracy without pruning ≈ 0.86\n",
    "    \n",
    "The tree using entropy performs better without pruning.\n",
    "\n",
    "* Gini with pruning vs without pruning:\n",
    "    - Accuracy with pruning ≈ 0.77\n",
    "    - Accuracy without pruning ≈ 0.88\n",
    "    \n",
    "The tree using gini also performs better without pruning.\n",
    "\n",
    "* Entropy without pruning vs Gini without pruning:\n",
    "    - Accuracy entropy: 0.86\n",
    "    - Accuracy Gini: 0.88\n",
    "    \n",
    "Both trees perform similarly, with Gini without pruning performing the best at 88% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4f040e",
   "metadata": {},
   "source": [
    "### 1.4.2 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "055984bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\u001b[1mGini without pruning on test dataset\u001b[0m \n",
      "Accuracy: 0.8375\n",
      "F1 score: 0.8713\n",
      "Number of nodes: 977\n",
      "Number of leaf nodes: 489\n",
      "Depth of the tree: 13\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set using the best model found in 1.4.1.\n",
    "test_predictions = get_predictions(best_tree, X_test)\n",
    "\n",
    "# Calculate the accuracy of the predictions.\n",
    "test_accuracy = sum(test_predictions == y_test) / len(y_test)\n",
    "\n",
    "# Calculate the F1 score of the predictions.\n",
    "test_f1 = f1_score(y_val, predictions)\n",
    "\n",
    "# Print the test set accuracy using the best model.\n",
    "print('-' * 40)\n",
    "pruning_status = 'with pruning' if best_prune_setting else 'without pruning'\n",
    "print(f'\\033[1m{best_measure.capitalize()} {pruning_status} on test dataset\\033[0m ')\n",
    "print(f'Accuracy: {test_accuracy:.4f}')\n",
    "print(f'F1 score: {test_f1:.4f}')\n",
    "# Print number of nodes, leaf nodes, and depth.\n",
    "print_tree_stats(tree)\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13238f10",
   "metadata": {},
   "source": [
    "The decision tree with Gini and without pruning had an accuracy of 0.84 on the test set. This is a more accurate estimate of real-world performance because the test set is previously unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80fa77",
   "metadata": {},
   "source": [
    "### 1.4.3 Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "376b2245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs are not constant.\n"
     ]
    }
   ],
   "source": [
    "# Check if the outputs are constant (if all predictions are the same).\n",
    "if len(set(test_predictions)) == 1:\n",
    "    print('The outputs are constant.')\n",
    "else:\n",
    "    print('The outputs are not constant.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868e45b",
   "metadata": {},
   "source": [
    "# 1.5 Compare to an Existing Implementation\n",
    "### 1.5.1 Training a Sklearn Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2d8ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a instance of the decision tree classifier.\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the decision tree classifier, save the start time and end time, and calculate training time.\n",
    "start_time_sklearn = time()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time_sklearn = time()\n",
    "train_time_sklearn = end_time_sklearn - start_time_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720a458",
   "metadata": {},
   "source": [
    "### 1.5.2 Training the Custom Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d479ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the custom decision tree, save the start time and end time, and calculate train time. \n",
    "# Using the best parameters found in 1.4.1.\n",
    "start_time_custom = time()\n",
    "custom_tree = learn(X_train, y_train, impurity_measure=best_measure, prune=best_prune_setting)\n",
    "end_time_custom = time()\n",
    "train_time_custom = end_time_custom - start_time_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b261d",
   "metadata": {},
   "source": [
    "### 1.5.3 Make Predictions and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d212af4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "\u001b[1mSklearn's DecisionTreeClassifier\u001b[0m \n",
      "Accuracy: 0.9000\n",
      "F1-score: 0.9006\n",
      "Training time: 0.0053 seconds\n",
      "Number of nodes: 501\n",
      "Number of leaf nodes: 251\n",
      "Depth of the tree: 18\n",
      "---------------------------------------------\n",
      "\u001b[1mCustom Decision Tree\u001b[0m \n",
      "Accuracy: 0.8375\n",
      "F1-score: 0.8344\n",
      "Training time: 0.9201 seconds\n",
      "Number of nodes: 977\n",
      "Number of leaf nodes: 489\n",
      "Depth of the tree: 13\n",
      "---------------------------------------------\n",
      "\u001b[1mComparison (Sklearn vs Custom)\u001b[0m \n",
      "Accuracy difference: -0.0625\n",
      "F1-score difference: -0.0662\n",
      "Training time difference: 0.9148 seconds\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set for both models.\n",
    "predictions_sklearn = clf.predict(X_test)\n",
    "predictions_custom = get_predictions(custom_tree, X_test)\n",
    "\n",
    "# Calculating accuracy for both models.\n",
    "accuracy_sklearn = accuracy_score(y_test, predictions_sklearn)\n",
    "accuracy_custom = accuracy_score(y_test, predictions_custom)\n",
    "\n",
    "# Calculate the F1 score for both models.\n",
    "f1_sklearn = f1_score(y_test, predictions_sklearn)\n",
    "f1_custom = f1_score(y_test, predictions_custom)\n",
    "\n",
    "print('-' * 45)\n",
    "print(f'\\033[1mSklearn\\'s DecisionTreeClassifier\\033[0m ')\n",
    "print(f\"Accuracy: {accuracy_sklearn:.4f}\")\n",
    "print(f\"F1-score: {f1_sklearn:.4f}\")\n",
    "print(f\"Training time: {train_time_sklearn:.4f} seconds\")\n",
    "# Print number of nodes, leaf nodes, and depth.\n",
    "print(f\"Number of nodes: {clf.tree_.node_count}\")\n",
    "print(f\"Number of leaf nodes: {clf.tree_.n_leaves}\")\n",
    "print(f\"Depth of the tree: {clf.tree_.max_depth}\")\n",
    "\n",
    "print('-' * 45)\n",
    "print(f'\\033[1mCustom Decision Tree\\033[0m ')\n",
    "print(f\"Accuracy: {accuracy_custom:.4f}\")\n",
    "print(f\"F1-score: {f1_custom:.4f}\")\n",
    "print(f\"Training time: {train_time_custom:.4f} seconds\")\n",
    "# Print number of nodes, leaf nodes, and depth.\n",
    "print_tree_stats(custom_tree)\n",
    "\n",
    "print('-' * 45)\n",
    "print(f'\\033[1mComparison (Sklearn vs Custom)\\033[0m ')\n",
    "print(f\"Accuracy difference: {(accuracy_custom - accuracy_sklearn):.4f}\")\n",
    "print(f\"F1-score difference: {(f1_custom - f1_sklearn):.4f}\")\n",
    "print(f\"Training time difference: {(train_time_custom - train_time_sklearn):.4f} seconds\")\n",
    "print('-' * 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad5bea",
   "metadata": {},
   "source": [
    "The custom decision tree has a 6% lower accuracy than Sklearn's DesicionTreeClassifier. The custom decision tree also takes longer time to train, and has almost the double amount of nodes and leaves. Sklear's DecisionTreeClassifier is deeper. This might suggest that the custom decision tree is either overfitting or using an unoptimized approach to split the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd802f",
   "metadata": {},
   "source": [
    "### 1.5.4 Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e56a2",
   "metadata": {},
   "source": [
    "* Accuracy\n",
    "    - The custom decision tree has an accuracy of 84%. This is lower than sklearn's accuracy of 90%.\n",
    "    - It might be small differences because of randomness, the rest might be because of a more optimized method to split features. \n",
    "* Speed\n",
    "    - Sklearn is around 150 times faster, and that is with the custom tree not using pruning (which would be even slower). This suggests that sklearn's implementation is a lot more optimized than the custom tree.\n",
    "* Overall\n",
    "    - Both models are performing decent, but Sklearn's model is a bit better at both accuracy and speed. While the speed does not matter on datasets of this size, it might matter on larger datasets. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
